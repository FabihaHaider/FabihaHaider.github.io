---
title: "ChitroJera: A Regionally Relevant Visual Question Answering Dataset for Bangla"
collection: publications
category: conferences
excerpt: 'In this research project, we explored the performance of Large Vision-Language Models on Bangla Visual Question Answering (VQA) tasks. Due to the lack of existing datasets in this domain, we developed a novel dataset specifically tailored for Bangla VQA. We conducted a series of experiments from multiple perspectives to effectively address our research objectives.'
date: 2025-09-15
venue: 'ECMLPKDD'
paperurl: 'https://arxiv.org/pdf/2410.14991'
---

Visual Question Answer (VQA) poses the problem of answering a natural language question about a visual context. Bangla, despite being a widely spoken language, is considered low-resource in the realm of VQA due to the lack of proper benchmarks, challenging models known to be performant in other languages. Furthermore, existing Bangla VQA datasets offer little regional relevance and are largely adapted from their foreign counterparts. To address these challenges, we introduce a largescale Bangla VQA dataset, ChitroJera, totaling over 15k samples from diverse and locally relevant data sources. We assess the performance of text encoders, image encoders, multimodal models, and our novel dual-encoder models. The experiments reveal that the pretrained dual-encoders outperform other models of their scale. We also evaluate the performance of current large vision language model (LVLMs) using prompt-based techniques, achieving the overall best performance. Given the underdeveloped state of existing datasets, we envision ChitroJera expanding the scope of Vision-Language tasks in Bangla.